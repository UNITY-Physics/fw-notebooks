{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6daa52d9-cf44-4765-a722-abfab008a2f4",
   "metadata": {},
   "source": [
    " # Pulling processed data from Gears\n",
    "Niall Bourke    \n",
    "14-11-24     \n",
    "\n",
    "This script is designed to automate pulling processed data within a Flywheel project, providing real-time updates on progress and estimated completion time. It iterates through all subjects and sessions in a Flywheel project, searches for specific analysis files based on user-defined criteria, downloads these files, and aggregates the data into a single CSV. Additionally, it uploads the final results to the project’s information tab for easy access.\n",
    "\n",
    "To make the process user-friendly, the script calculates the total number of steps at the beginning and, throughout execution, displays the percentage of completion and estimated time remaining. This allows users to monitor progress, especially useful when handling large datasets that may require significant time to process. Each part of the code is structured to help users understand how the data is managed, downloaded, and saved, ensuring both transparency and efficiency in data handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea01125-574d-4869-bb8a-145786ba1c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pathvalidate\n",
      "  Downloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: pathvalidate\n",
      "Successfully installed pathvalidate-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pathvalidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fd6c14-df77-450f-9d0d-32fa5bae4261",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea3f3b0-08de-4b62-bf34-aef50d7bb1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import flywheel\n",
    "from pathlib import Path\n",
    "import pathvalidate as pv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652fb067-1036-4c2b-95e8-df79c61a7675",
   "metadata": {},
   "source": [
    "### Step 2: Define variables and paths for script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c10b1c4-3301-4b63-aece-95e6ffb7f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = fw_project\n",
    "\n",
    "# Filters\n",
    "gear = 'ants-segmentation' # 'recon-all-clinical' # recode this as variable that user selects in config\n",
    "gearVersion = '0.3.0' #'0.3.2'\n",
    "timestampFilter = datetime(2024, 7, 10, 0, 0, 0, 0, pytz.UTC) # Date before which we want to filter analyses (i.e. only get analyses run after this date)\n",
    "fileName_tag = 'volume'\n",
    "\n",
    "# --- prep output --- #\n",
    "\n",
    "# Create a work directory in our local \"home\" directory\n",
    "work_dir = Path(Path.home() / 'Data/', platform='auto')\n",
    "# If it doesn't exist, create it\n",
    "if not work_dir.exists():\n",
    "    work_dir.mkdir(parents = True)\n",
    "# Create a custom path for our project (we may run this on other projects in the future) and create if it doesn't exist\n",
    "project_path = pv.sanitize_filepath(work_dir/project.label/gear, platform='auto')\n",
    "if not project_path.exists():\n",
    "    project_path.mkdir(parents = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb236a0b-baf2-4730-a992-e31a3d2b2f23",
   "metadata": {},
   "source": [
    "# --- Find the results --- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e36d8627-9cba-4754-a05e-c600dc20ea6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DEMO-001, 2023-06-09 13_54_24\n",
      "Progress: 100.00% | Estimated Time Remaining: 0.00 minutes\n",
      "pulling: ants-segmentation 0.3.0\n",
      "/home/jovyan/Data/ISMRM_UNITY_DEMO/ants-segmentation/DEMO-001/2023-06-09 13_54_24/sub_DEMO_001_ses_2023_06_09_rec_T2w_mrr_fast_volumes.csv\n",
      "downloading file 2023-06-09 13_54_24 ants-segmentation 08/29/2024 09:12:05\n",
      "Execution time: 11.210002660751343 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the start time\n",
    "st = time.time()\n",
    "\n",
    "# Preallocate lists\n",
    "df = []\n",
    "sub = []\n",
    "ses = []\n",
    "acq = []\n",
    "\n",
    "# Calculate total number of subjects and sessions\n",
    "total_subjects = sum(1 for _ in project.subjects.iter())\n",
    "total_sessions = sum(1 for subject in project.subjects.iter() for _ in subject.sessions.iter())\n",
    "total_steps = total_subjects * total_sessions\n",
    "completed_steps = 0\n",
    "\n",
    "# Iterate through all subjects in the project and find the results\n",
    "for subject in project.subjects.iter():\n",
    "    subject = subject.reload()\n",
    "    sub_label = subject.label\n",
    "    for session in subject.sessions.iter():\n",
    "        session = session.reload()\n",
    "        ses_label = session.label\n",
    "        completed_steps += 1  # Increment completed steps\n",
    "        \n",
    "        # Calculate progress and estimate remaining time\n",
    "        elapsed_time = time.time() - st\n",
    "        progress = (completed_steps / total_steps) * 100\n",
    "        estimated_total_time = elapsed_time / (completed_steps / total_steps)\n",
    "        remaining_time = estimated_total_time - elapsed_time\n",
    "\n",
    "        print(f\"Processing {sub_label}, {ses_label}\")\n",
    "        print(f\"Progress: {progress:.2f}% | Estimated Time Remaining: {remaining_time / 60:.2f} minutes\")\n",
    "\n",
    "        for analysis in session.analyses:\n",
    "            if analysis.gear_info is not None and analysis.gear_info.name == gear and analysis.gear_info.version == gearVersion and analysis.created > timestampFilter:\n",
    "                print(\"pulling:\", gear, gearVersion)\n",
    "                for analysis_file in analysis.files:\n",
    "                    if fileName_tag in analysis_file.name:\n",
    "                        file = analysis_file\n",
    "                        file = file.reload()\n",
    "                        \n",
    "                        # Sanitize our filename and parent path\n",
    "                        download_dir = pv.sanitize_filepath(Path(project_path) / sub_label / ses_label, platform='auto')   \n",
    "                        fileName = file.name \n",
    "\n",
    "                        # Create the path\n",
    "                        if not download_dir.exists():\n",
    "                            download_dir.mkdir(parents=True)\n",
    "                        download_path = download_dir / fileName\n",
    "                        print(download_path)\n",
    "\n",
    "                        # Download the file\n",
    "                        print('downloading file', ses_label, analysis.label)\n",
    "                        file.download(download_path)\n",
    "\n",
    "                        # Add subject to dataframe\n",
    "                        with open(download_path) as csv_file:\n",
    "                            results = pd.read_csv(csv_file, index_col=None, header=0) \n",
    "                            df.append(results)\n",
    "\n",
    "        # --- Save output --- #\n",
    "        try:\n",
    "            outname = project.label.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "            filename = f\"{outname}-{gear}-{gearVersion}-volumes.csv\"\n",
    "            \n",
    "            # Concatenate and save DataFrame\n",
    "            df = pd.concat(df, axis=0, ignore_index=True)\n",
    "            outdir = Path(project_path) / filename\n",
    "            df.to_csv(outdir)\n",
    "\n",
    "            # Uploads a file to the project information tab\n",
    "            project.upload_file(str(outdir))\n",
    "        except:\n",
    "            print(f\"Failed to upload results for {project.label} to project info tab\")\n",
    "            print(\"Check that if analysis was run, and that there are results to upload\")\n",
    "            continue\n",
    "\n",
    "# Get the end time\n",
    "et = time.time()\n",
    "# Get the execution time\n",
    "total_elapsed_time = et - st\n",
    "print('Execution time:', total_elapsed_time, 'seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f1cd0-a9ad-4d69-a75b-5d8211699c22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Walkthrough: Flywheel Data Processing Script\n",
    "\n",
    "\n",
    "### Step 1: Import Required Libraries\n",
    "\n",
    "We start by importing necessary libraries:\n",
    "\n",
    "```python\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "```\n",
    "\n",
    "### Step 2: Track Start Time\n",
    "\n",
    "```python\n",
    "st = time.time()\n",
    "```\n",
    "This initializes a variable st to store the script's start time, allowing us to calculate the total runtime later.\n",
    "\n",
    "### Step 3: Preallocate Lists for Data Storage\n",
    "\n",
    "```python\n",
    "df = []\n",
    "sub = []\n",
    "ses = []\n",
    "acq = []\n",
    "```\n",
    "These lists are used to store downloaded data and relevant subject and session information.\n",
    "\n",
    "### Step 4: Calculate Total Steps\n",
    "To estimate completion progress, we first calculate the total number of subject-session combinations. This helps us know how many \"steps\" the script will take to finish.\n",
    "\n",
    "```python\n",
    "total_subjects = sum(1 for _ in project.subjects.iter())\n",
    "total_sessions = sum(1 for subject in project.subjects.iter() for _ in subject.sessions.iter())\n",
    "total_steps = total_subjects * total_sessions\n",
    "completed_steps = 0\n",
    "```\n",
    "\n",
    "### Step 5: Iterate Through Subjects and Sessions\n",
    "The main part of the script loops through each subject and session, processing data as it goes.\n",
    "\n",
    "```python\n",
    "for subject in project.subjects.iter():\n",
    "    subject = subject.reload()\n",
    "    sub_label = subject.label\n",
    "    for session in subject.sessions.iter():\n",
    "        session = session.reload()\n",
    "        ses_label = session.label\n",
    "        completed_steps += 1  # Increment completed steps\n",
    "```\n",
    "\n",
    "### Step 6: Calculate Progress and Remaining Time\n",
    "Within each loop iteration, we calculate the percentage of completion and estimate the remaining time.\n",
    "\n",
    "```python\n",
    "elapsed_time = time.time() - st\n",
    "progress = (completed_steps / total_steps) * 100\n",
    "estimated_total_time = elapsed_time / (completed_steps / total_steps)\n",
    "remaining_time = estimated_total_time - elapsed_time\n",
    "\n",
    "print(f\"Processing {sub_label}, {ses_label}\")\n",
    "print(f\"Progress: {progress:.2f}% | Estimated Time Remaining: {remaining_time / 60:.2f} minutes\")\n",
    "```\n",
    "This provides the user with an ongoing update of the script’s progress, helping them understand how much longer the script is likely to take.\n",
    "\n",
    "### Step 7: Download and Process Analysis Files\n",
    "The script then checks if each session has a specific analysis file to download. If it finds the file, it downloads it and appends the data to our list df.\n",
    "\n",
    "```python\n",
    "for analysis in session.analyses:\n",
    "    if analysis.gear_info is not None and analysis.gear_info.name == gear and analysis.gear_info.version == gearVersion and analysis.created > timestampFilter:\n",
    "        for analysis_file in analysis.files:\n",
    "            if fileName_tag in analysis_file.name:\n",
    "                # Download file and append data to `df`\n",
    "```\n",
    "\n",
    "### Step 8: Save and Upload Results\n",
    "Once all files are downloaded and combined into a DataFrame, the script saves the data to a CSV file. It then uploads the file to the project information tab in Flywheel.\n",
    "    \n",
    "```python\n",
    "try:\n",
    "    outname = project.label.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    filename = f\"{outname}-{gear}-{gearVersion}-volumes.csv\"\n",
    "    \n",
    "    # Concatenate and save DataFrame\n",
    "    df = pd.concat(df, axis=0, ignore_index=True)\n",
    "    outdir = Path(project_path) / filename\n",
    "    df.to_csv(outdir)\n",
    "\n",
    "    # Uploads a file to the project information tab\n",
    "    project.upload_file(str(outdir))\n",
    "except:\n",
    "    print(f\"Failed to upload results for {project.label} to project info tab\")\n",
    "    print(\"Check that if analysis was run, and that there are results to upload\")\n",
    "    continue\n",
    "```\n",
    "\n",
    "### Step 9: Calculate Total Execution Time\n",
    "Finally, the script calculates and prints the total time taken to complete all processing.\n",
    "\n",
    "```python\n",
    "et = time.time()\n",
    "total_elapsed_time = et - st\n",
    "print('Execution time:', total_elapsed_time, 'seconds')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b6b7c7-e283-4fe4-b690-6ed9274500d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
