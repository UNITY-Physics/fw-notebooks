{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Brain Parcellation Visualization  \n",
    "\n",
    "### Overview  \n",
    "This notebook visualizes brain parcellations using **FreeSurferâ€™s aparc+aseg.mgz** file, overlaying region labels on a native anatomical scan. Each brain region is assigned a unique color, allowing clear distinction between structures.  \n",
    "\n",
    "### Future Enhancements  \n",
    "- Ensure **left and right hemisphere regions have the same color**  \n",
    "- Integrate **FreeSurfer's predefined colors** from `FreeSurferColorLUT.txt`  \n",
    "\n",
    "### Output  \n",
    "The visualization displays distinct brain regions in unique colors, overlaid on the anatomical scan.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nibabel nilearn reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn import image, plotting\n",
    "import nibabel.freesurfer as fs\n",
    "from nilearn.image import resample_to_img\n",
    "import matplotlib.colors as mcolors\n",
    "from nibabel.freesurfer import read_annot\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import re\n",
    "import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import flywheel\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.utils import ImageReader\n",
    "\n",
    "today = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, connect to your Flywheel instance: If running this from Flywheel JupyterLab workspace, you will not need to do this step, and this cell can be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(dotenv_path=os.path.expanduser(\"~/.zshrc\"), override=True)\n",
    "\n",
    "api_key = os.environ.get('FW_CLI_API_KEY')\n",
    "fw = flywheel.Client(api_key=api_key)\n",
    "display(f\"User: {fw.get_current_user().firstname} {fw.get_current_user().lastname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_label = ... # fill in the project name \n",
    "project = fw.projects.find_one(f'label={project_label}')\n",
    "project = project.reload()\n",
    "subjects = project.subjects.find_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subjects,gear):\n",
    "    \n",
    "    for subject in subjects:\n",
    "        subject = subject.reload()\n",
    "        sub_label = subject.label\n",
    "        \n",
    "        for session in subject.sessions.iter():\n",
    "            session = session.reload()\n",
    "            ses_label = session.label\n",
    "\n",
    "            analyses = session.analyses\n",
    "\n",
    "            # If there are no analyses containers, we know that this gear was not run\n",
    "            if len(analyses) == 0:\n",
    "                run = 'False'\n",
    "                status = 'NA'\n",
    "                print('No analysis containers')\n",
    "            else:\n",
    "\n",
    "                matches = [asys for asys in analyses if asys.gear_info.get('name') == gear]\n",
    "\n",
    "                print(\"Matches: \", len(matches))\n",
    "                # If there are no matches, the gear didn't run\n",
    "                if len(matches) == 0:\n",
    "                    run = 'False'\n",
    "                    status = 'NA'\n",
    "                # If there is one match, that's our target\n",
    "                elif len(matches) == 1:\n",
    "                    run = 'True'\n",
    "                    status = matches[0].job.get('state')\n",
    "                    print(status)\n",
    "\n",
    "                    for file in matches[0].files:  \n",
    "                        print(file.name)\n",
    "                        if file.name.endswith('aparc+aseg.nii.gz') or file.name.endswith('synthSR.nii.gz') or re.search('mrr-axireg.*\\.nii.gz', file.name) or re.search('.*\\.zip', file.name):\n",
    "                            parcellation = file\n",
    "                            print(\"Found \", file.name)\n",
    "                            if file :\n",
    "                                download_dir = Path(f'{sub_label}/{ses_label}/')\n",
    "                                download_dir.mkdir(parents=True,exist_ok=True)\n",
    "                                download_path = os.path.join(download_dir , parcellation.name)\n",
    "                                parcellation.download(download_path)\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "                    last_run_date = max([asys.created for asys in matches])\n",
    "                    last_run_analysis = [asys for asys in matches if asys.created == last_run_date]\n",
    "\n",
    "                    # There should only be one exact match\n",
    "                    last_run_analysis = last_run_analysis[0]\n",
    "\n",
    "                    run = 'True'\n",
    "                    status = last_run_analysis.job.get('state')\n",
    "\n",
    "                    for file in last_run_analysis.files:\n",
    "                        if file.name.endswith('aparc+aseg.nii.gz') or file.name.endswith('synthSR.nii.gz') or re.search('mrr-axireg.*\\.nii.gz', file.name) or re.search('.*\\.zip', file.name):\n",
    "                            parcellation = file\n",
    "                            print(\"Found \", file.name)\n",
    "                            if file :\n",
    "                                download_dir = Path(f'{sub_label}/{ses_label}/')\n",
    "                                download_dir.mkdir(parents=True,exist_ok=True)\n",
    "                                download_path = os.path.join(download_dir , parcellation.name)\n",
    "                                parcellation.download(download_path)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get output from the MRR and recon-all gears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gear = \"mrr\"\n",
    "subjects = project.subjects.iter()\n",
    "get_data(subjects,gear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gear = \"recon-all-clinical\"\n",
    "subjects = project.subjects.iter()\n",
    "get_data(subjects,gear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthSR_scan_path = \"\" \n",
    "native_scan_path = \"\"\n",
    "segmentation_path = \"\"\n",
    "subjects = project.subjects.iter()\n",
    "\n",
    "for subject in subjects:\n",
    "    subject = subject.reload()\n",
    "    sub_label = subject.label\n",
    "    print(sub_label)\n",
    "    \n",
    "    for session in subject.sessions.iter():\n",
    "        session = session.reload()\n",
    "        ses_label = session.label\n",
    "        \n",
    "        try:\n",
    "    \n",
    "            files = os.listdir(path=f\"{sub_label}/{ses_label}\")\n",
    "\n",
    "            for file in files:\n",
    "                if file.endswith('aparc+aseg.nii.gz'):\n",
    "                    segmentation_path = os.path.join(f\"{sub_label}/{ses_label}\",file)\n",
    "\n",
    "\n",
    "                elif file.endswith('synthSR.nii.gz'):\n",
    "                    synthSR_scan_path = os.path.join(f\"{sub_label}/{ses_label}\",file)\n",
    "\n",
    "\n",
    "                elif re.search('mrr-axireg.*\\.nii.gz', file):\n",
    "                    native_scan_path = os.path.join(f\"{sub_label}/{ses_label}\",file)\n",
    "\n",
    "\n",
    "            native_scan = nib.load(native_scan_path)\n",
    "            segmentation = nib.load(segmentation_path)\n",
    "\n",
    "            if native_scan and segmentation: #if files are not empty\n",
    "\n",
    "                # Resample the segmentation to match the native scan space if needed\n",
    "                resampled_segmentation = image.resample_to_img(segmentation, native_scan, interpolation=\"nearest\")\n",
    "\n",
    "                plotting.plot_anat(\n",
    "                    native_scan_path,\n",
    "                    title=f\"{sub_label} - {ses_label} \",\n",
    "                    display_mode=\"ortho\",\n",
    "                    output_file=f\"{sub_label}/{ses_label}/{sub_label}_native_scan.png\"\n",
    "                )\n",
    "\n",
    "                plotting.plot_roi(\n",
    "                    resampled_segmentation,\n",
    "                    bg_img=native_scan_path,\n",
    "                    \n",
    "                    alpha=0.3,  \n",
    "                    cmap=\"cool\",  \n",
    "                    threshold=0.5, \n",
    "                    title=\"Overlayed Segmentation (native)\" ,\n",
    "                    output_file=f\"{sub_label}/{ses_label}/{sub_label}_Overlayed Segmentation (native).png\"\n",
    "                )\n",
    "\n",
    "                plotting.plot_roi(\n",
    "                    resampled_segmentation,\n",
    "                    bg_img=synthSR_scan_path,\n",
    "                    title=\"Overlayed Segmentation (synthSR)\",\n",
    "                    alpha=0.3,  # Adjust transparency\n",
    "                    cmap=\"cool\",\n",
    "                    threshold=0.5,  # Remove noisy boundaries below the threshold,\n",
    "                    output_file=f\"{sub_label}/{ses_label}/{sub_label}_Overlayed Segmentation (synthSR).png\"\n",
    "                )\n",
    "\n",
    "                image1_path = f\"{sub_label}/{ses_label}/{sub_label}_native_scan.png\"\n",
    "                image2_path = f\"{sub_label}/{ses_label}/{sub_label}_Overlayed Segmentation (native).png\"\n",
    "                image3_path = f\"{sub_label}/{ses_label}/{sub_label}_Overlayed Segmentation (synthSR).png\"\n",
    "\n",
    "                img1 = mpimg.imread(image1_path)\n",
    "                img2 = mpimg.imread(image2_path)\n",
    "                img3 = mpimg.imread(image3_path)\n",
    "\n",
    "                fig, axes = plt.subplots(3, 1, figsize=(8, 15))\n",
    "\n",
    "                axes[0].imshow(img1)\n",
    "                axes[0].axis('off') \n",
    "\n",
    "                axes[1].imshow(img2)\n",
    "                axes[1].axis('off')\n",
    "\n",
    "                axes[2].imshow(img3)\n",
    "                axes[2].axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{sub_label}/{ses_label}/{sub_label}_segmentation_overlays_vertical.png\", dpi=300,bbox_inches='tight')\n",
    "                print(\"Plot saved for \", sub_label)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print('Exception found: ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthSR_scan_path = \"\" \n",
    "native_scan_path = \"\"\n",
    "segmentation_path = \"\"\n",
    "\n",
    "# Constants\n",
    "page_width, page_height = letter\n",
    "border_margin = 1  # Margin from top/bottom\n",
    "plot_height = 150    # Approximate height of each plot in the PDF\n",
    "plot_spacing = 1    # Spacing between plots\n",
    "usable_height = page_height - 2 * border_margin  # Usable page height\n",
    "plots_per_page = usable_height // (plot_height + plot_spacing)  # Max plots per page\n",
    "\n",
    "# Create a new PDF\n",
    "output_pdf = f\"Segmentation_QC_Report_{project.label}.pdf\"\n",
    "pdf = canvas.Canvas(output_pdf, pagesize=letter)\n",
    "\n",
    "# Vertical position tracker\n",
    "y_position = page_height - border_margin\n",
    "\n",
    "# Iterate through subjects\n",
    "subjects = project.subjects.iter()\n",
    "files = []\n",
    "for subject in subjects:\n",
    "    \n",
    "    subject = subject.reload()\n",
    "    sub_label = subject.label\n",
    "    \n",
    "    for session in subject.sessions.iter():\n",
    "        session = session.reload()\n",
    "        ses_label = session.label\n",
    "        \n",
    "        try:\n",
    "            plot_path = f\"{sub_label}/{ses_label}/{sub_label}_segmentation_overlays_vertical.png\"\n",
    "\n",
    "            image = ImageReader(plot_path)\n",
    "            # Get the width and height of the image\n",
    "            img_width, img_height = image.getSize()\n",
    "\n",
    "            # Add plot to PDF\n",
    "            if y_position - plot_height < border_margin:  # Check if a new page is needed\n",
    "                pdf.showPage()\n",
    "                y_position = page_height - border_margin  # Reset y_position\n",
    "\n",
    "            pdf.drawImage(plot_path, border_margin, y_position - plot_height, width=page_width - 2 * border_margin, height=plot_height)\n",
    "\n",
    "            # Update y_position\n",
    "            y_position -= plot_height + plot_spacing\n",
    "        except Exception as e:\n",
    "            print(\"Exception caught: \", e)\n",
    "\n",
    "\n",
    "\n",
    "# Save the PDF\n",
    "pdf.save()\n",
    "print(f\"PDF saved to {output_pdf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_label = \"Visualise Parcellations\"\n",
    "analysis = session.add_analysis(label=analysis_label)\n",
    "analysis.upload_output(output_pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".unityEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
